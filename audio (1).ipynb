{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NFR3OX4jBCXk",
        "outputId": "45ea015c-600a-4663-b536-342d1390107c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/mdmab0/audio-dataset/v1/some_folder/*.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'/root/.cache/kagglehub/datasets/mdmab0/audio-dataset/v1/some_folder/*.wav'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os # Import the 'os' module\n",
        "\n",
        "# Check if the directory is already mounted by lookingp for 'MyDrive'\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print(\"Google Drive is already mounted at /content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3HTKPpSCQ50",
        "outputId": "d3b29aed-e4a0-447d-a3f2-9f4b568b44d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "import kagglehub # Importing kagglehub here to define 'path'\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mdmab0/audio-dataset\") # Defining 'path' before using it\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Source folder where audio files are stored\n",
        "source_folder = Path(path)\n",
        "\n",
        "# Destination in your Google Drive\n",
        "destination_folder = Path('/content/drive/MyDrive/archive (20)')\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "destination_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy .wav files\n",
        "for file in source_folder.rglob(\"*.wav\"):\n",
        "    shutil.copy(file, destination_folder)\n",
        "\n",
        "print(f\"Copied all .wav files to: {destination_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rRFEzAIChbQ",
        "outputId": "f022fcb4-ea0f-4c67-c9c2-01f873bab457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mdmab0/audio-dataset?dataset_version_number=6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118M/118M [00:00<00:00, 171MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mdmab0/audio-dataset/versions/6\n",
            "Copied all .wav files to: /content/drive/MyDrive/archive (20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, file in enumerate(source_folder.rglob(\"*.wav\")):\n",
        "    new_name = f\"audio_{i:04d}.wav\"\n",
        "    shutil.copy(file, destination_folder / new_name)\n"
      ],
      "metadata": {
        "id": "_DIXqRZSCoHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa matplotlib soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94j6apS2CxBZ",
        "outputId": "c864ed2f-6dfa-4c4f-b6b2-94a6f00e5999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "bAo3KFM7Cxv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Source and destination folders\n",
        "source_folder = Path(\"/content/drive/MyDrive/archive (20)\")\n",
        "output_folder = Path(\"/content/drive/MyDrive/audio_processed\")\n",
        "output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Function to save waveform, spectrogram, and MFCC\n",
        "def process_audio(file_path, save_folder):\n",
        "    filename = Path(file_path).stem\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Waveform\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    librosa.display.waveshow(audio, sr=sr)\n",
        "    plt.title(f'Waveform - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_waveform.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Spectrogram\n",
        "    spec = librosa.stft(audio)\n",
        "    spec_db = librosa.amplitude_to_db(abs(spec))\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(spec_db, sr=sr, x_axis='time', y_axis='hz')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(f'Spectrogram - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_spectrogram.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mfcc, x_axis='time')\n",
        "    plt.colorbar()\n",
        "    plt.title(f'MFCC - {filename}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_folder / f\"{filename}_mfcc.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Processed: {filename}\")\n",
        "\n",
        "# Limit to 500 files\n",
        "max_files = 200\n",
        "count = 0\n",
        "\n",
        "for wav_file in source_folder.rglob(\"*.wav\"):\n",
        "    if count >= max_files:\n",
        "        break\n",
        "    process_audio(wav_file, output_folder)\n",
        "    count += 1\n",
        "\n",
        "print(f\"✅ Processed {count} audio files and saved results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBCTSoJmC1Wc",
        "outputId": "792c833d-e319-4c5d-d9b8-df9bab3b2858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: not_hs_phrase_30_f\n",
            "Processed: hs_audio_11_2\n",
            "Processed: hs_audio_5_24\n",
            "Processed: not_hs_phrase_241_f\n",
            "Processed: not_hs_phrase_234_f\n",
            "Processed: hs_audio_word_16_6_f\n",
            "Processed: hs_audio_9_4\n",
            "Processed: not_hs_phrase_545\n",
            "Processed: not_hs_phrase_62\n",
            "Processed: hs_audio_14_8\n",
            "Processed: hs_audio_5_19\n",
            "Processed: not_hs_phrase_45\n",
            "Processed: not_hs_phrase_181\n",
            "Processed: not_hs_phrase_202\n",
            "Processed: hs_audio_5_23\n",
            "Processed: hs_audio_11_5_f\n",
            "Processed: not_hs_phrase_37_f\n",
            "Processed: hs_audio_9_3\n",
            "Processed: not_hs_phrase_131_f\n",
            "Processed: hs_audio_word_16_3\n",
            "Processed: hs_audio_word_27_3_f\n",
            "Processed: not_hs_phrase_276\n",
            "Processed: not_hs_phrase_505\n",
            "Processed: not_hs_phrase_340_f\n",
            "Processed: hs_audio_word_24_5\n",
            "Processed: hs_audio_word_24_27_f\n",
            "Processed: hs_audio_15_12_f\n",
            "Processed: hs_audio_word_23_12\n",
            "Processed: not_hs_phrase_452\n",
            "Processed: hs_audio_word_31_7_f\n",
            "Processed: hs_audio_word_31_9\n",
            "Processed: not_hs_audio_8_6\n",
            "Processed: not_hs_phrase_586_f\n",
            "Processed: not_hs_phrase_325\n",
            "Processed: hs_audio_9_8\n",
            "Processed: not_hs_phrase_359_f\n",
            "Processed: not_hs_phrase_321\n",
            "Processed: not_hs_phrase_342_f\n",
            "Processed: hs_audio_word_28_23\n",
            "Processed: hs_audio_15_25_f\n",
            "Processed: not_hs_phrase_421\n",
            "Processed: not_hs_phrase_90\n",
            "Processed: not_hs_phrase_474\n",
            "Processed: hs_audio_15_14_f\n",
            "Processed: not_hs_phrase_300\n",
            "Processed: not_hs_phrase_12\n",
            "Processed: not_hs_phrase_392_f\n",
            "Processed: not_hs_phrase_415\n",
            "Processed: not_hs_phrase_182\n",
            "Processed: hs_audio_13_1\n",
            "Processed: not_hs_phrase_253\n",
            "Processed: not_hs_phrase_285_f\n",
            "Processed: hs_audio_word_26_18\n",
            "Processed: not_hs_phrase_448\n",
            "Processed: hs_audio_word_30_9\n",
            "Processed: not_hs_phrase_129_f\n",
            "Processed: hs_audio_word_18_4_f\n",
            "Processed: not_hs_phrase_142\n",
            "Processed: hs_audio_word_25_6_f\n",
            "Processed: hs_audio_5_11\n",
            "Processed: not_hs_phrase_71\n",
            "Processed: hs_audio_11_21_f\n",
            "Processed: hs_audio_word_16_1\n",
            "Processed: not_hs_phrase_386_f\n",
            "Processed: not_hs_audio_8_28\n",
            "Processed: hs_audio_word_25_1\n",
            "Processed: hs_audio_word_2_2_f\n",
            "Processed: not_hs_phrase_163_f\n",
            "Processed: not_hs_phrase_456\n",
            "Processed: hs_audio_word_26_17\n",
            "Processed: hs_audio_word_20_8\n",
            "Processed: not_hs_phrase_77_f\n",
            "Processed: hs_audio_word_6_4_f\n",
            "Processed: not_hs_phrase_485\n",
            "Processed: hs_audio_word_23_3_f\n",
            "Processed: not_hs_phrase_366\n",
            "Processed: hs_audio_5_51\n",
            "Processed: hs_audio_word_22_12\n",
            "Processed: hs_audio_word_27_9\n",
            "Processed: not_hs_phrase_339_f\n",
            "Processed: hs_audio_word_21_1\n",
            "Processed: not_hs_phrase_535\n",
            "Processed: hs_audio_word_27_7\n",
            "Processed: not_hs_phrase_290\n",
            "Processed: hs_audio_word_24_13_f\n",
            "Processed: not_hs_phrase_8_f\n",
            "Processed: not_hs_phrase_441\n",
            "Processed: hs_audio_5_32\n",
            "Processed: not_hs_phrase_568\n",
            "Processed: not_hs_phrase_564\n",
            "Processed: hs_audio_word_3_4_f\n",
            "Processed: not_hs_phrase_271_f\n",
            "Processed: not_hs_phrase_214\n",
            "Processed: not_hs_phrase_295\n",
            "Processed: not_hs_phrase_469\n",
            "Processed: not_hs_phrase_149\n",
            "Processed: hs_audio_word_15_9_f\n",
            "Processed: not_hs_phrase_518\n",
            "Processed: hs_audio_word_30_5_f\n",
            "Processed: hs_audio_word_23_5_f\n",
            "Processed: hs_audio_word_28_2_f\n",
            "Processed: hs_audio_word_10_8\n",
            "Processed: not_hs_phrase_190\n",
            "Processed: not_hs_phrase_176_f\n",
            "Processed: not_hs_audio_8_10\n",
            "Processed: not_hs_phrase_222\n",
            "Processed: hs_audio_word_26_13\n",
            "Processed: hs_audio_4_4\n",
            "Processed: not_hs_phrase_434_f\n",
            "Processed: hs_audio_word_9_9_f\n",
            "Processed: hs_audio_5_27\n",
            "Processed: not_hs_phrase_74_f\n",
            "Processed: not_hs_phrase_464\n",
            "Processed: hs_audio_2_1\n",
            "Processed: hs_audio_word_31_12_f\n",
            "Processed: not_hs_phrase_164_f\n",
            "Processed: hs_audio_word_27_2\n",
            "Processed: not_hs_phrase_385_f\n",
            "Processed: hs_audio_15_27_f\n",
            "Processed: hs_audio_word_31_15_f\n",
            "Processed: not_hs_phrase_144_f\n",
            "Processed: not_hs_phrase_451\n",
            "Processed: not_hs_phrase_520\n",
            "Processed: not_hs_phrase_4_f\n",
            "Processed: not_hs_audio_8_33\n",
            "Processed: not_hs_phrase_121_f\n",
            "Processed: not_hs_phrase_320\n",
            "Processed: hs_audio_word_9_4_f\n",
            "Processed: not_hs_phrase_317_f\n",
            "Processed: not_hs_phrase_481_f\n",
            "Processed: not_hs_phrase_399\n",
            "Processed: hs_audio_word_12_4\n",
            "Processed: hs_audio_word_31_4_f\n",
            "Processed: hs_audio_word_29_1\n",
            "Processed: not_hs_phrase_238\n",
            "Processed: not_hs_phrase_141_f\n",
            "Processed: not_hs_phrase_2\n",
            "Processed: hs_audio_5_28\n",
            "Processed: not_hs_phrase_588_f\n",
            "Processed: hs_audio_14_21\n",
            "Processed: hs_audio_word_32_11\n",
            "Processed: hs_audio_word_22_4_f\n",
            "Processed: hs_audio_15_7_f\n",
            "Processed: hs_audio_5_3\n",
            "Processed: not_hs_phrase_551_f\n",
            "Processed: hs_audio_4_5\n",
            "Processed: not_hs_phrase_332\n",
            "Processed: hs_audio_5_37\n",
            "Processed: hs_audio_13_2\n",
            "Processed: hs_audio_15_15_f\n",
            "Processed: not_hs_phrase_455\n",
            "Processed: not_hs_phrase_263_f\n",
            "Processed: hs_audio_14_14\n",
            "Processed: not_hs_phrase_227_f\n",
            "Processed: hs_audio_word_28_14\n",
            "Processed: hs_audio_word_13_13\n",
            "Processed: not_hs_phrase_549\n",
            "Processed: hs_audio_word_29_5_f\n",
            "Processed: not_hs_phrase_174\n",
            "Processed: hs_audio_word_12_2_f\n",
            "Processed: hs_audio_word_30_14_f\n",
            "Processed: not_hs_phrase_418_f\n",
            "Processed: not_hs_audio_8_30\n",
            "Processed: not_hs_phrase_498\n",
            "Processed: not_hs_audio_4_1\n",
            "Processed: hs_audio_word_28_22_f\n",
            "Processed: not_hs_phrase_22_f\n",
            "Processed: not_hs_phrase_462_f\n",
            "Processed: not_hs_phrase_524_f\n",
            "Processed: hs_audio_word_11_3\n",
            "Processed: not_hs_phrase_305\n",
            "Processed: not_hs_phrase_154\n",
            "Processed: not_hs_phrase_303_f\n",
            "Processed: hs_audio_word_13_11\n",
            "Processed: not_hs_phrase_507\n",
            "Processed: not_hs_phrase_352\n",
            "Processed: not_hs_phrase_403_f\n",
            "Processed: hs_audio_9_7\n",
            "Processed: not_hs_phrase_61\n",
            "Processed: not_hs_phrase_442\n",
            "Processed: hs_audio_word_23_9\n",
            "Processed: not_hs_phrase_54_f\n",
            "Processed: not_hs_phrase_585\n",
            "Processed: hs_audio_15_16_f\n",
            "Processed: not_hs_phrase_260\n",
            "Processed: not_hs_phrase_145\n",
            "Processed: hs_audio_14_2\n",
            "Processed: not_hs_phrase_119\n",
            "Processed: hs_audio_word_15_2\n",
            "Processed: hs_audio_word_20_9_f\n",
            "Processed: hs_audio_word_1_8\n",
            "Processed: not_hs_phrase_198_f\n",
            "Processed: not_hs_phrase_534\n",
            "Processed: not_hs_phrase_26\n",
            "Processed: hs_audio_word_15_7\n",
            "Processed: not_hs_phrase_205\n",
            "Processed: not_hs_phrase_289_f\n",
            "Processed: hs_audio_word_19_1\n",
            "Processed: hs_audio_11_22_f\n",
            "Processed: hs_audio_4_12\n",
            "✅ Processed 200 audio files and saved results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "data_path = Path(\"/content/drive/MyDrive/archive (20)\")\n",
        "all_files = list(data_path.glob(\"*.wav\"))[:200]  # Limit to 200 for training\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "max_len = 100\n",
        "n_mfcc = 40\n",
        "\n",
        "for file_path in all_files:\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc).T\n",
        "\n",
        "    if mfcc.shape[0] >= max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        pad = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad), (0, 0)), mode='constant')\n",
        "\n",
        "    X.append(mfcc)\n",
        "    y.append(0)  # Default label (binary or dummy for now)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ Loaded MFCC features from\", len(X), \"files\")\n",
        "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZomXdkn4C8I0",
        "outputId": "5bf8d76e-a592-4ff7-cdd8-4e60c13cdf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded MFCC features from 200 files\n",
            "X shape: (200, 100, 40) | y shape: (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape input to match LSTM [samples, time steps, features]\n",
        "# Already in (samples, 100, 40)\n",
        "\n",
        "# 2. Build the LSTM model\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(X.shape[1], X.shape[2])),  # Mask padded time steps\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the model\n",
        "history = model.fit(X_train, y_train, epochs=15, batch_size=16,\n",
        "                    validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# 5. Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"\\n✅ Test Accuracy: {acc:.4f} | Test Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5EVp4GIDBOI",
        "outputId": "a23e6f55-6ca3-4c2b-8bb7-489261761340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 278ms/step - accuracy: 0.9484 - loss: 0.3510 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
            "Epoch 2/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 3/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 8.1158e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 9.0565e-04 - val_accuracy: 1.0000 - val_loss: 4.2659e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 5.6161e-04 - val_accuracy: 1.0000 - val_loss: 2.9863e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.9945e-04 - val_accuracy: 1.0000 - val_loss: 2.3955e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 3.6689e-04 - val_accuracy: 1.0000 - val_loss: 2.0401e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 2.4879e-04 - val_accuracy: 1.0000 - val_loss: 1.8014e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 2.2626e-04 - val_accuracy: 1.0000 - val_loss: 1.6163e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 3.1862e-04 - val_accuracy: 1.0000 - val_loss: 1.4446e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 2.3822e-04 - val_accuracy: 1.0000 - val_loss: 1.2973e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 2.2014e-04 - val_accuracy: 1.0000 - val_loss: 1.1599e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 1.5823e-04 - val_accuracy: 1.0000 - val_loss: 1.0450e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 1.9165e-04 - val_accuracy: 1.0000 - val_loss: 9.4195e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 1.5245e-04 - val_accuracy: 1.0000 - val_loss: 8.4934e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 8.5461e-05\n",
            "\n",
            "✅ Test Accuracy: 1.0000 | Test Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(X_test)\n",
        "# Convert probabilities to binary class labels (threshold = 0.5)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Flatten arrays\n",
        "y_pred = y_pred.flatten()\n",
        "y_test = y_test.flatten()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"🧩 Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMx6hYAbDCVN",
        "outputId": "55b2d850-6806-4fba-f111-c565dd6dcaa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        40\n",
            "\n",
            "    accuracy                         1.0000        40\n",
            "   macro avg     1.0000    1.0000    1.0000        40\n",
            "weighted avg     1.0000    1.0000    1.0000        40\n",
            "\n",
            "🧩 Confusion Matrix:\n",
            "[[40]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Load MFCC features\n",
        "data_path = Path(\"/content/drive/MyDrive/archive (20)\")\n",
        "all_files = list(data_path.glob(\"*.wav\"))[:200]  # Limit to 200 files\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "max_len = 100\n",
        "n_mfcc = 40\n",
        "\n",
        "for file_path in all_files:\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc).T\n",
        "\n",
        "    if mfcc.shape[0] >= max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        pad = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad), (0, 0)), mode='constant')\n",
        "\n",
        "    X.append(mfcc)\n",
        "    y.append(0 if '0' in file_path.stem else 1)  # Example label logic\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"✅ Loaded MFCCs: {X.shape}, Labels: {np.unique(y, return_counts=True)}\")\n",
        "\n",
        "# Step 2: K-Fold Cross Validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "all_reports = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}/5\")\n",
        "\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=(X.shape[1], X.shape[2])),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_probs = model.predict(X_val)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "    report = classification_report(y_val, y_pred, digits=4, output_dict=True)\n",
        "    all_reports.append(report)\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val, y_pred, digits=4))\n",
        "\n",
        "# Step 3: Average Metrics\n",
        "avg_acc = np.mean([r.get('accuracy', 0) for r in all_reports])\n",
        "avg_prec_0 = np.mean([r.get('0', {}).get('precision', 0) for r in all_reports])\n",
        "avg_prec_1 = np.mean([r.get('1', {}).get('precision', 0) for r in all_reports])\n",
        "avg_recall_0 = np.mean([r.get('0', {}).get('recall', 0) for r in all_reports])\n",
        "avg_recall_1 = np.mean([r.get('1', {}).get('recall', 0) for r in all_reports])\n",
        "\n",
        "print(\"\\n📊 Average Scores Across Folds:\")\n",
        "print(f\"Avg Accuracy       : {avg_acc:.4f}\")\n",
        "print(f\"Avg Precision [0/1]: {avg_prec_0:.4f} / {avg_prec_1:.4f}\")\n",
        "print(f\"Avg Recall    [0/1]: {avg_recall_0:.4f} / {avg_recall_1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh5THOZ9DEuX",
        "outputId": "de9f6cc2-dbb3-4c45-e365-9014428ee1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded MFCCs: (200, 100, 40), Labels: (array([0, 1]), array([ 24, 176]))\n",
            "\n",
            "📂 Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step\n",
            "Confusion Matrix:\n",
            "[[ 1  4]\n",
            " [ 4 31]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2000    0.2000    0.2000         5\n",
            "           1     0.8857    0.8857    0.8857        35\n",
            "\n",
            "    accuracy                         0.8000        40\n",
            "   macro avg     0.5429    0.5429    0.5429        40\n",
            "weighted avg     0.8000    0.8000    0.8000        40\n",
            "\n",
            "\n",
            "📂 Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432ms/step\n",
            "Confusion Matrix:\n",
            "[[ 1  4]\n",
            " [ 5 30]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1667    0.2000    0.1818         5\n",
            "           1     0.8824    0.8571    0.8696        35\n",
            "\n",
            "    accuracy                         0.7750        40\n",
            "   macro avg     0.5245    0.5286    0.5257        40\n",
            "weighted avg     0.7929    0.7750    0.7836        40\n",
            "\n",
            "\n",
            "📂 Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468ms/step\n",
            "Confusion Matrix:\n",
            "[[ 0  5]\n",
            " [ 4 31]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000         5\n",
            "           1     0.8611    0.8857    0.8732        35\n",
            "\n",
            "    accuracy                         0.7750        40\n",
            "   macro avg     0.4306    0.4429    0.4366        40\n",
            "weighted avg     0.7535    0.7750    0.7641        40\n",
            "\n",
            "\n",
            "📂 Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451ms/step\n",
            "Confusion Matrix:\n",
            "[[ 1  4]\n",
            " [ 7 28]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1250    0.2000    0.1538         5\n",
            "           1     0.8750    0.8000    0.8358        35\n",
            "\n",
            "    accuracy                         0.7250        40\n",
            "   macro avg     0.5000    0.5000    0.4948        40\n",
            "weighted avg     0.7812    0.7250    0.7506        40\n",
            "\n",
            "\n",
            "📂 Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step\n",
            "Confusion Matrix:\n",
            "[[ 1  3]\n",
            " [ 6 30]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1429    0.2500    0.1818         4\n",
            "           1     0.9091    0.8333    0.8696        36\n",
            "\n",
            "    accuracy                         0.7750        40\n",
            "   macro avg     0.5260    0.5417    0.5257        40\n",
            "weighted avg     0.8325    0.7750    0.8008        40\n",
            "\n",
            "\n",
            "📊 Average Scores Across Folds:\n",
            "Avg Accuracy       : 0.7700\n",
            "Avg Precision [0/1]: 0.1269 / 0.8827\n",
            "Avg Recall    [0/1]: 0.1700 / 0.8524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict\n",
        "y_pred_probs = model.predict(X_val)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Print numeric confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Confusion Matrix - Fold {fold+1}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "c_8rLCrmDJdH",
        "outputId": "ec76f095-bb3f-4c00-9244-912bb050f1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Confusion Matrix:\n",
            "[[ 1  3]\n",
            " [ 6 30]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}